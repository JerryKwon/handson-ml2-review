{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 케라스를 사용한 인공 신경망 소개\n",
    "\n",
    "## 10.1. 생물학적 뉴런에서 인공 뉴런까지\n",
    "\n",
    "인공신경망(ANN)은 1943년의 <a href=\"http://aiplaybook.a16z.com/reference-material/mcculloch-pitts-1943-neural-networks.pdf\">특정 논문</a>에서 소개되었다. 위의 논문에서 소개된 논리적인 개념을 바탕으로 1960년부터 현재에 이르기까지 발전해오고 있다. 그러나 발전에 있어서 인공신경망은 학습을 진행하는데 있어서 마주한 제약으로 인해 어려움을 겪었다. 그리고 지금은 다시 인공 신경망이 부흥하고 있는데 왜 부흥하고 있는가? 그 이유는 아래와 같다.\n",
    "\n",
    "1. 신경망을 훈련하기 위한 데이터셋의 확보\n",
    "2. 90년대 이후 발전한 컴퓨터 하드웨어\n",
    "3. 훈련 알고리즘의 향상\n",
    "4. 지역 최적점(Local Minima)문제의 해결책 탐구\n",
    "5. 투자와 진보의 선순환\n",
    "\n",
    "### 10.1.3. 퍼셉트론\n",
    "\n",
    "퍼셉트론은 1943년에 논리적인 신경망 구조가 정의된 후, 인공 뉴런이라는 개념을 토대로 1957년에 제안된 가장 간단한 인공 신경망 구조이다. 퍼셉트론은 TLU(Threshold Logic Unit) 또는 LTU(Linear Threshold Unit)라고 불리는 인공 뉴런을 기반으로 만들어졌다. \n",
    "\n",
    "![TLU](../../img/TLU.png)\n",
    "\n",
    "퍼셉트론을 살펴보기전 TLU에 대해서 살펴보자. TLU는 N개의 입력 $I_1 ... I_n$이 있고 이는 각각에 대응되는 가중치 $W_1 ... W_n$의 가중치와 연관되어 있다. 그리고 TLU는 각 입력과 가중치를 곱하여 합을한 후에 계단함수인 Threshold 함수 $T$를 통해 결과를 출력한다.\n",
    "\n",
    "$h_w(x) = step(z)$\n",
    "\n",
    "퍼셉트론에서 가장 널리 사용되는 계단 함수는 헤비사이드(heavyside function) 계단함수이며, 종종 부호(sign function) 함수로 대신 사용하기도 한다.\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/f1783c84465f7a602fae566c34efa63f48c84212\" />\n",
    "<div align=\"center\" style=\"margin-top:20px\">헤비사이드 함수</div>\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/bf38b06707caef9847d668ee9022678cc649f421\" />\n",
    "<div align=\"center\" style=\"margin-top:20px\">부호 함수</div>\n",
    "\n",
    "여기서 TLU를 훈련한다는 것은 최적은 가중치 $W_1, W_2 ... W_n$을 찾는것이다.\n",
    "\n",
    "퍼셉트론은 은닉층이 하나인 TLU로 구성된다. 그리고 모든 입력값은 은닉층의 뉴런과 모두 연결되어 있기 때문에 fully-connected layer 또는 dense layer(Keras에서 모듈을 부르는 이름)라고 한다.\n",
    "\n",
    "![MLP_w_bias](../../img/MLP_w_bias.png)\n",
    "\n",
    "입력층에서는 입력 뉴런으로 구성된다. 입력 뉴런은 간단히 입력 값에 아무런 조치 없이 바로 통과시키는 뉴런이다. 그리고 입력층에서는 편향 특성이 함께 입력값으로 투입한다. 그러나 편향값은 신경망 정의시 뉴런 개수를 정의할 떄 보통 제외하고 정의한다.\n",
    "\n",
    "<div align=\"left\" style=\"padding-left:30px; padding-top:30px\">\n",
    "<span>$h_w,b(X) = \\phi(XW+b)$</span>\n",
    "    \n",
    "<span>**식. 완전 연결 층의 출력 계산**</span>\n",
    "</div>\n",
    "\n",
    "* $X$: 입력 특성의 행렬\n",
    "* 가중치 행렬 $W$: 편향 뉴련을 제외한 모든 연결가중치\n",
    "* 편향 벡터 $b$: 편향 뉴런과 인공 뉴런 사이의 모든 연결 가중치\n",
    "* $\\phi$: 활성화함수\n",
    "\n",
    "그렇다면 퍼셉트론은 어떻게 훈련되는가? 이는 헤브의 규칙(Hebb's rule)에서 영감을 많이 받았다. 이는 두 뉴런이 동시에 활성활될 때마다 이들 사이의 연결 가중치가 증가하는 경향이 있다는 것이고, 이는 헤브의 규칙(또는 헤브 학습)으로 알려졌다. \n",
    "\n",
    "만약 첫 번째 샘플이 퍼셉트론에 입력으로 주어져서 학습한 후, 잘못된 결과 값을 return한 뉴런에 대해 올바른 예측을 할 수 있도록 입력에 대한 연결된 가중치를 강화 하는 것이다.\n",
    "\n",
    "<div align=\"left\" style=\"padding-left:30px; padding-top:30px\">\n",
    "<span>$w_{i,j}^{(next\\_step)} = w_{i,j} + \\eta(y_j - \\hat{y}_j)x_i$</span>\n",
    "    \n",
    "<span>**식. 퍼셉트론 학습 규칙(가중치 업데이트)**</span>\n",
    "</div>\n",
    "\n",
    "* $w_i,j$는 i번째 입력 뉴런과 j번째 출력 뉴런 사이를 연결하는 가중치\n",
    "* $x_i$는 현재 훈련 샘플의 i번째 뉴런의 입력값\n",
    "* $\\hat{y}_j$는 현재 훈련 샘플의 j번째 출력 뉴런의 출력값\n",
    "* $y_j$는 현재 훈련 샘플의 j번째 출력 뉴런의 타깃값\n",
    "* $\\eta$는 학습률\n",
    "\n",
    "그러나 퍼셉트론도 뉴런의 결정 경계가 선형이므로 복잡한 패턴을 학습하지 못한다. 그에 대한 심각한 약점은 배타적 논리합(XOR)를 예측하지 못한다는 것이다. \n",
    "\n",
    "아래의 그림과 같이 선형으로 위 또는 아래로 구분시 절대 0과 1의 결과를 구분할 수 없다는 것을 알 수 있다.\n",
    "\n",
    "![XOR_table](../../img/XOR_table.png)\n",
    "<div align=\"center\" style=\"margin-top:20px\">배타적 논리합(XOR) 연산표</div>\n",
    "\n",
    "![XOR_problem](../../img/XOR_problem.gif)\n",
    "<div align=\"center\" style=\"margin-top:20px\">배타적 논리합(XOR) 문제</div>\n",
    "\n",
    "추후에 하나의 퍼셉트론을 여러개의 층으로 구성하는 MLP 구조에서는 XOR 문제를 해결할 수 있다는 것을 밝혀냈다.\n",
    "\n",
    "### 10.1.4. 다층 퍼셉트론과 역전파\n",
    "\n",
    "![MLP_sturcture](../../img/MLP_structure.jpg)\n",
    "<div align=\"center\" style=\"margin-top:20px\">활성화 함수</div>\n",
    "\n",
    "이제는 위에서 언급했던 여러 계층의 퍼셉트론으로 구성된 MLP(Multiple Layer Perceptron)에 대해서 살펴보자. MLP도 기존의 퍼셉트론과 동일하게 입력 계층과 출력 계층이 있다. 그러나 이전과 달리 첫 번째 입력 계층의 출력값이 은닉층이라고 불리는 계층에 입력으로 사용되고 은닉층의 결과 값은 출력계층의 입력으로 연결된다. 이렇게 한 개 이상의 은닉계층을 가지는 신경망을 심층 신경망(Deep Nueral Network;DNN)이라고 한다. \n",
    "\n",
    "그런데, 다중 퍼셉트론을 사용하며 문제가 발생했다. 퍼셉트론을 학습한다는 것은 입력과 출력 사이의 가중치를 학습한다는 것인데, 다층 구조에서는 이 가중치를 학습할 수 있는 방안이 없었기 때문이다. 1986년 <a href=\"https://apps.dtic.mil/dtic/tr/fulltext/u2/a164453.pdf\">역전파 훈련 알고리즘을 소개하는 논문</a>이 등장하면서 DNN의 가중치 학습 문제를 해결하고 다시 신경망이 발전할 수 있는 계기가 되었다. 역전파 알고리즘은 경사하강법을 통해 신경망의 흐름을 정방향과 역방향으로 통과시킴으로써 모델 파라미터에 대한 네트워크 오차의 경사를 계산하는 알고리즘이다. 이로 인해, 어떻게 가중치와 편향값을 변경해야할 지 알수 있게 되었다.\n",
    "\n",
    "역전파 알고리즘에서는,\n",
    "\n",
    "1. 기존의 학습과 동일하게 입력값을 신경망에 투입함으로써 마지막 출력 계층까지 통과하여 출력값을 반환\n",
    "2. 얻은 출력값을 기존의 결과값과 비교하여 오차를 계산\n",
    "3. 출력으로 연결된 각각의 가중치가 오차에 기여한 정도를 계산(연쇄 법칙[chain rule]을 활용)\n",
    "4. 3번 절차와 동일하게 연쇄 법칙을 통해 그전 출력으로 연결된 가중치의 기여도 및 오차 그라디언트 계산\n",
    "5. 4번 절차를 반복하여 입력 계층까지 도달\n",
    "6. 경사하강법을 통해 신경망 전반적으로 계산된 오차 그라디언트를 사용하여 네트워크의 모든 연결 가중치를 수정한다.\n",
    "\n",
    "간단히 요약하자면,\n",
    "\n",
    "역전파 알고리즘은 각 훈련 샘플에대해 예측을 만들어 정방향 오차를 계산, 역방향으로 각 층을 거치면서 출력 오차에 기여한 정도를 계산, 출력 오차 기여도를 줄이는 방햐으로 가중치를 조정하는 것이다.\n",
    "\n",
    "그리고 역전파 알고리즘과 함께, 계단 함수에 새로운 함수들이 사용되기 시작했다.\n",
    "\n",
    "기존에 heavyside 및 sign 함수를 버리게 된 이유는, 계단함수를 통해 얻은 결과값들이 모든 구간에서 도함수가 0임으로 경사하강법을 적용할 수 없었기 때문이다. \n",
    "\n",
    "![activation_funcs](../../img/sigmoid_tanh_relu.png)\n",
    "<div align=\"center\" style=\"margin-top:20px\">활성화 함수</div>\n",
    "\n",
    "* sigmoid\n",
    "\n",
    "$\\sigma(z)=1/(1+exp(-z))$\n",
    "* tanh: 로지스틱 함수와 같은 S자 모양으로 연속적이고 미분 가능하다. 그러나 -1과 1사이의 결과값을 return하는 것이 차이점이며, 범위적 특성 때문에 훈련 초기의 각 층의 출력을 원점 근처로 모으는 경향이 있다. 위와 같은 특성은 종종 빠르게 결과에 수렴할 수 있도록 한다.\n",
    "\n",
    "$tanh(z)=2\\sigma(2z)-1$\n",
    "* ReLU: ReLU 함수는 연속적이지만 z=0인 구간에서 미분가능하지 않다. 위의 두 함수와 달리 z<0인 경우에는 도함수가 0이다. 그러나 실제로 잘 작동하고 계산속도가 빠르다는 장점이 있어 기본 활성화 함수로 사용한다. 그리고 출력에 최대값이 없음으로 경사하강법의 일부 문제를 보완한다.\n",
    "\n",
    "$ReLU(z)=max(0,z)$\n",
    "\n",
    "####  Q. 왜 활성화 함수가 필요한가?\n",
    "\n",
    "선형변환 함수를 여러겹 붙이더라도 결과적으로는 선형함수가 된다. 그래서 비선형성을 추가하지 않는다면 복잡한 문제를 해결할 수 없다. 따라서, 비선형성을 활성함수로써 추가하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2. [분류] MNIST 이미지 분류기 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.path.abspath(os.path.dirname(os.path.abspath('__file__'))),'output','models')\n",
    "model_file = os.path.join(model_path,'FashionDNN.pt')\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.FashionMNIST(\n",
    "    root = '../data/',\n",
    "    train = True,\n",
    "#     download = True,\n",
    "    download = False,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root = '../data/',\n",
    "    train = False,\n",
    "#     download = True,\n",
    "    download = False,\n",
    "    transform = transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(train_dataset)))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "split = int(np.floor(0.2 * len(train_dataset)))\n",
    "train_sample = SubsetRandomSampler(indices[:split])\n",
    "valid_sample = SubsetRandomSampler(indices[split:])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, sampler=train_sample, batch_size=BATCH_SIZE)\n",
    "valid_loader = torch.utils.data.DataLoader(train_dataset, sampler=valid_sample, batch_size=BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,'id: 45808; label: Pullover')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_num = random.randint(0,len(train_dataset))\n",
    "img = train_dataset.data[rand_num].numpy()\n",
    "label_idx = train_dataset.targets[rand_num]\n",
    "label = classes[label_idx] \n",
    "\n",
    "plt.imshow(img,cmap=\"gray\")\n",
    "plt.suptitle('id: %d; label: %s'%(rand_num,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleDNN,self).__init__()\n",
    "        self.dnn = nn.Sequential(\n",
    "                            nn.Linear(784,256),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(256,64),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(64,10),\n",
    "                            nn.Sigmoid()\n",
    "                        )\n",
    "    def forward(self, x):\n",
    "        out = self.dnn(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, criterion, optimizer):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    train_corrects = 0\n",
    "    \n",
    "    model.train()\n",
    "     \n",
    "    for batch_num, (inputs, labels) in enumerate(train_loader):\n",
    "        if DEVICE == \"cuda\":\n",
    "            model = model.to(DEVICE)\n",
    "            inputs = inputs.to(DEVICE)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        inputs = inputs.view(-1,784)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss\n",
    "        \n",
    "        preds = torch.argmax(outputs,axis=1)\n",
    "        preds_corrects = torch.sum(labels==preds).item()\n",
    "        train_corrects += preds_corrects\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0.0\n",
    "        valid_corrects = 0\n",
    "        best_loss = np.inf\n",
    "        for batch_num, (inputs, labels) in enumerate(valid_loader):\n",
    "            inputs = inputs.view(-1,784)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss\n",
    "            \n",
    "            preds = torch.argmax(outputs, axis=1)\n",
    "            preds_corrects = torch.sum(labels==preds).item()\n",
    "            valid_corrects += preds_corrects\n",
    "            \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    valid_loss = valid_loss / len(valid_loader)\n",
    "    \n",
    "    train_acc = train_corrects / len(train_loader.dataset)\n",
    "    valid_acc = valid_corrects / len(valid_loader.dataset)\n",
    "    \n",
    "    return train_loss, valid_loss, train_acc, valid_acc\n",
    "    \n",
    "def predict(model, test_loader, criterion):\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    test_corrects = 0\n",
    "    prediction = list()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (inputs, labels) in enumerate(test_loader):\n",
    "            if DEVICE == \"cuda\":\n",
    "                model = model.to(DEVICE)\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                \n",
    "            inputs = inputs.view(-1,784)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "            test_loss += loss\n",
    "            \n",
    "            preds = torch.argmax(outputs,axis=1)\n",
    "            prediction.append(preds.data.numpy())\n",
    "            preds_corrects = torch.sum(preds == labels).item()\n",
    "            test_corrects += preds_corrects\n",
    "            \n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_acc = test_corrects / len(test_loader.dataset)\n",
    "    prediction= np.concatenate(np.array(prediction))\n",
    "    \n",
    "    return test_loss, test_acc, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleDNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297ec775fbed4ec3830ebccc55c37530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1/5; train_loss: 1.6977; valid_loss: 1.6358; train_acc: 0.1202; valid_acc: 0.5284\n",
      "valid_loss broken from inf to 1.6358\n",
      "EPOCH: 2/5; train_loss: 1.6183; valid_loss: 1.6060; train_acc: 0.1496; valid_acc: 0.6167\n",
      "valid_loss broken from 1.6358 to 1.6060\n",
      "EPOCH: 3/5; train_loss: 1.5967; valid_loss: 1.5986; train_acc: 0.1547; valid_acc: 0.6230\n",
      "valid_loss broken from 1.6060 to 1.5986\n",
      "EPOCH: 4/5; train_loss: 1.5871; valid_loss: 1.6000; train_acc: 0.1591; valid_acc: 0.6235\n",
      "EPOCH: 5/5; train_loss: 1.5834; valid_loss: 1.5822; train_acc: 0.1608; valid_acc: 0.6477\n",
      "valid_loss broken from 1.5986 to 1.5822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(model_path):\n",
    "    os.path.mkdir(model_path)\n",
    "    \n",
    "if os.path.isfile(os.path.join(model_path,'FashionDNN.pt')):\n",
    "    print(\"Utilizing Previous Model\")\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "best_loss = np.inf\n",
    "for epoch in tqdm_notebook(range(EPOCHS)):\n",
    "    train_loss, valid_loss, train_acc, valid_acc= train(model, train_loader, valid_loader, criterion, optimizer)\n",
    "    print(\"EPOCH: {}/{}; train_loss: {:.4f}; valid_loss: {:.4f}; train_acc: {:.4f}; valid_acc: {:.4f}\".format(epoch+1,EPOCHS,train_loss,valid_loss,train_acc,valid_acc))\n",
    "    if valid_loss < best_loss:\n",
    "        print(\"valid_loss broken from {:.4f} to {:.4f}\".format(best_loss,valid_loss))\n",
    "        torch.save(model.state_dict(),model_file)\n",
    "        best_loss = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.5892;test_acc: 0.7969\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, predictions = predict(model, test_loader, criterion)\n",
    "print(\"test_loss: {:.4f}; test_acc: {:.4f}\".format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3. [회귀] 캘리포니아 집값 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
